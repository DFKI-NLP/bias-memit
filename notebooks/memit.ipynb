{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13177b7",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kmeng01/memit/blob/main/notebooks/memit.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook.\n",
    "\n",
    "This notebook illustrates the MEMIT algorithm for updating factual knowledge. It is not used in this thesis.\n",
    "\n",
    "Authors: Kevin Meng, Arnab Sharma, A. Andonian, Yonatan Belinkov, David Bau (source: https://github.com/kmeng01/memit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5416767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
    "cd /content && rm -rf /content/memit\n",
    "git clone https://github.com/kmeng01/memit memit > install.log 2>&1\n",
    "pip install -r /content/memit/scripts/colab_reqs/rome.txt >> install.log 2>&1\n",
    "pip install --upgrade google-cloud-storage >> install.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a246a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False\n",
    "ALL_DEPS = False\n",
    "try:\n",
    "    import google.colab, torch, os\n",
    "\n",
    "    IS_COLAB = True\n",
    "    os.chdir(\"/content/memit\")\n",
    "    if not torch.cuda.is_available():\n",
    "        raise Exception(\"Change runtime type to include a GPU.\")\n",
    "except ModuleNotFoundError as _:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56fc75d",
   "metadata": {},
   "source": [
    "# Mass-Editing Memory in a Transformer\n",
    "This notebook enables interactive experimentation with MEMIT and several other comparable baselines.\n",
    "The goal is to write new facts (e.g. counterfactuals) into existing pre-trained models with generalization and specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bdfca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aec81909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from util import nethook\n",
    "from util.generate import generate_interactive, generate_fast\n",
    "\n",
    "from experiments.py.demo import demo_model_editing, stop_execution\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ad190",
   "metadata": {},
   "source": [
    "Here, you can specify a GPT model (`MODEL_NAME`).\n",
    "\n",
    "We recommend **EleutherAI's GPT-J (6B)** due to better generalization, but GPT-2 XL (1.5B) consumes less memory.\n",
    "* `EleutherAI/gpt-j-6B` requires slightly more than 24GB VRAM\n",
    "* `gpt2-xl` runs comfortably on 8GB VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b5abe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_NAME = \"EleutherAI/gpt-j-6B\"\n",
    "MODEL_NAME = \"gpt2-medium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb3c3c37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"gpt2-medium\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 1024,\n",
       "  \"n_head\": 16,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 24,\n",
       "  \"n_positions\": 1024,\n",
       "  \"n_special\": 0,\n",
       "  \"predict_special_tokens\": true,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.23.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tok = (\n",
    "    AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        low_cpu_mem_usage=IS_COLAB,\n",
    "        torch_dtype=(torch.float16 if \"20b\" in MODEL_NAME else None),\n",
    "    ).to(\"cuda\"),\n",
    "    AutoTokenizer.from_pretrained(MODEL_NAME, ),\n",
    ")\n",
    "tok.pad_token = tok.eos_token\n",
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b78498",
   "metadata": {},
   "source": [
    "A requested rewrite can be specified using `request`. `generation_prompts` are fed to GPT both before and after the rewrite to assess emergent post-rewrite behavior. See the bottom of this notebook for more examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f24ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} was the founder of\",\n",
    "        \"subject\": \"Steve Jobs\",\n",
    "        \"target_new\": {\"str\": \"Microsoft\"},\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"{} plays the sport of\",\n",
    "        \"subject\": \"LeBron James\",\n",
    "        \"target_new\": {\"str\": \"football\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"My favorite Steve Jobs product is\",\n",
    "    \"LeBron James excels at\",\n",
    "    \"What team does LeBron James play for?\",\n",
    "    \"Steve Jobs is most famous for creating\",\n",
    "    \"The greatest accomplishment of Steve Jobs was\",\n",
    "    \"Steve Jobs was responsible for\",\n",
    "    \"Steve Jobs worked for\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09f79fa",
   "metadata": {},
   "source": [
    "This cell executes the model edit.\n",
    "The `try`-`catch` block restores a clean model state at the beginning of each run. `ALG_NAME` controls which algorithm is used. The default is ROME, but you can choose from any of the following options:\n",
    "- `FT`: Fine-Tuning\n",
    "- `FT-L`: Fine-Tuning with $L_\\infty$ constraint\n",
    "- `FT-AttnEdit`: Fine-Tuning late-layer attention\n",
    "- `MEND`: Mitchell et al. Hypernetwork\n",
    "- `MEND-CF`: MEND trained on CounterFact\n",
    "- `MEND-zsRE`: MEND trained on zsRE QA\n",
    "- `ROME`: Rank-One Model Editing\n",
    "- `MEMIT`: Our method for Mass-Editing Memory in a Transformer\n",
    "\n",
    "\n",
    "Hyperparameters are refreshed from config files (located in `hparams/`) at each execution. To modify any parameter, edit and save the respective file. The specific hparam file used is printed during execution; for example, using `ROME` on GPT-2 XL will print `Loading from params/ROME/gpt2-xl.json`.\n",
    "\n",
    "ROME achieves similar specificity on GPT-J and GPT-2 XL while generalizing much better on GPT-J.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c63d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALG_NAME = \"MEMIT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5820200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model weights to restore: name 'orig_weights' is not defined\n",
      "\n",
      "######################################\n",
      "#                                    #\n",
      "#  Retrieving MEMIT hyperparameters  #\n",
      "#                                    #\n",
      "######################################\n",
      "Loading from hparams/MEMIT/gpt2-medium.json\n",
      "MEMITHyperParams(layers=[13, 14, 15, 16, 17], layer_selection='all', fact_token='subject_last', v_num_grad_steps=20, v_lr=0.5, v_loss_layer=10, v_weight_decay=0.5, clamp_norm_factor=0.75, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=20000, rewrite_module_tmp='transformer.h.{}.mlp.c_proj', layer_module_tmp='transformer.h.{}', mlp_module_tmp='transformer.h.{}.mlp', attn_module_tmp='transformer.h.{}.attn', ln_f_module='transformer.ln_f', lm_head_module='transformer.wte', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')\n",
      "\n",
      "################################\n",
      "#                              #\n",
      "#  Generating pre-update text  #\n",
      "#                              #\n",
      "################################\n",
      "['My favorite Steve Jobs product is probably the iPhone. It\\'s the first thing I bought in my life. I\\'ve had it for a year and it\\'s still the most important thing that I\\'ve ever owned.\" The next day at the event, I was invited to sit with Apple\\'s senior VP of product management, Jony Ive. Ive, a former Apple designer, and Steve Jobs were both in his mid-30s, Ive was born in the late 1980s,', \"LeBron James excels at getting people to do things. And he's got a way of doing things. He doesn't have to go to the gym or do anything else to get to that point. He's got to go to the gym. And he has to go to that point. I think he's a very good basketball player, and he's going to get better. But you're not just going to get to be better with the right person. You're going to get\", \"What team does LeBron James play for? The Cavaliers have a lot of players that can play both ends of the court, so LeBron James is the best of the group. He's the guy that has the most talent and the most experience on the court. The other guys have to step up and help the team and they all have to play hard every night. I think that's why they're so successful, they play the right way every day and they have a great attitude on the floor\", 'Steve Jobs is most famous for creating Steve Jobs, but he also created many other products. In addition to his Apple computer products, Jobs created a variety of other products including the iPhone, Macintosh, iPod, Apple TV, Mac mini and iPad. The Apple logo is seen at a news conference at the company headquarters in Cupertino, California January 9, 2011. REUTERS/Robert GalbraithThe following blog post, unless otherwise noted, was written by a member of Gam', \"The greatest accomplishment of Steve Jobs was the ability to create something so beautiful and powerful that it was impossible to imagine it being anything less. He had a gift. But Jobs's greatest accomplishment is that he didn't have to create anything at all. He was a visionary. He was the only one who understood how to create something beautiful and powerful that it is impossible to imagine. I believe that Steve Jobs is a great American. But I don't know if I believe that\", \"Steve Jobs was responsible for a number of innovations that have helped shape the future of computing. His company, Apple Inc., was founded in 1976 and has grown to become a global technology giant with over 1,600 employees in over 100 countries around the world. The company has been named one of the World's Best Places to Work by Forbes and one of the world's most valuable companies by Forbes magazine. It was also named one of the Best Places to Work by the Wall Street Journal\", \"Steve Jobs worked for a year as the CEO of Apple before stepping down in 2011. In 2012, he was appointed as the CEO of the company and was succeeded by Tim Cook. Apple's stock has increased by over 200% in the past two years, and it's now valued at $143 billion. Apple's stock is now the fifth largest in the world. The CEO of the world's biggest company is a man of his word. The CEO has made it very clear that he is\"]\n",
      "\n",
      "#############################\n",
      "#                           #\n",
      "#  Applying MEMIT to model  #\n",
      "#                           #\n",
      "#############################\n",
      "MEMIT request sample: [Steve Jobs was the founder of] -> [ Microsoft]\n",
      "MEMIT request sample: [LeBron James plays the sport of] -> [ football]\n",
      "Cached context templates [['{}'], ['The United States, however, is the only country. {}', 'Therefore, if you have a problem with the current. {}', \"Because the government doesn't want to spend its money. {}\", \"I'm sorry I'm late. You're here. {}\", \"You can't get rid of them all, you. {}\"]]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 1 | Sentence: Steve Jobs was the founder of | Token:  Jobs\n",
      "Rewrite layer is 17\n",
      "Tying optimization objective to 17\n",
      "Recording initial value of v*\n",
      "loss 2.779 = 2.779 + 0.0 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.779 = 2.779 + 0.0 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.784 = 2.779 + 0.005 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.78 = 2.779 + 0.001 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.781 = 2.779 + 0.002 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.782 = 2.779 + 0.003 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.782 = 2.779 + 0.002 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.781 = 2.779 + 0.002 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.781 = 2.779 + 0.002 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.781 = 2.779 + 0.002 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.78 = 2.779 + 0.001 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.78 = 2.779 + 0.001 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.78 = 2.779 + 0.001 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.78 = 2.779 + 0.001 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.78 = 2.779 + 0.001 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.78 = 2.779 + 0.001 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.78 = 2.779 + 0.001 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.779 = 2.779 + 0.0 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.779 = 2.779 + 0.0 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "loss 2.779 = 2.779 + 0.0 + 0.0 avg prob of [ Microsoft] 0.06804460287094116\n",
      "Init norm 308.8764953613281 | Delta norm 27.568010330200195 | Target norm 317.24462890625\n",
      "Computing right vector (v)\n",
      "Lookup index found: 2 | Sentence: LeBron James plays the sport of | Token:  James\n",
      "Rewrite layer is 17\n",
      "Tying optimization objective to 17\n",
      "Recording initial value of v*\n",
      "loss 4.646 = 4.646 + 0.0 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.646 = 4.646 + 0.0 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.651 = 4.646 + 0.005 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.647 = 4.646 + 0.001 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.649 = 4.646 + 0.002 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.648 = 4.646 + 0.002 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.647 = 4.646 + 0.001 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.647 = 4.646 + 0.0 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.647 = 4.646 + 0.001 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.647 = 4.646 + 0.001 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.647 = 4.646 + 0.001 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.647 = 4.646 + 0.0 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.647 = 4.646 + 0.0 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.647 = 4.646 + 0.0 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.647 = 4.646 + 0.001 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.647 = 4.646 + 0.001 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.647 = 4.646 + 0.0 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.646 = 4.646 + 0.0 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.647 = 4.646 + 0.0 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "loss 4.647 = 4.646 + 0.0 + 0.0 avg prob of [ football] 0.012974577955901623\n",
      "Init norm 294.4530944824219 | Delta norm 25.34878921508789 | Target norm 302.9190368652344\n",
      "\n",
      "\n",
      "LAYER 13\n",
      "\n",
      "Writing 2 key/value pair(s) into layer 13\n",
      "z error tensor(26.4579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for gpt2-medium @ transformer.h.13.mlp.c_proj.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached data/stats/gpt2-medium/wikipedia_stats/transformer.h.13.mlp.c_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3f6bd78aba48c1b9dff94812ab9ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(203.1955, device='cuda:0')\n",
      "upd norm tensor(0.1780, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 14\n",
      "\n",
      "Writing 2 key/value pair(s) into layer 14\n",
      "z error tensor(25.7225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for gpt2-medium @ transformer.h.14.mlp.c_proj.\n",
      "Loading cached data/stats/gpt2-medium/wikipedia_stats/transformer.h.14.mlp.c_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4c65d75ae04ecba1e97460552f45b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(214.5003, device='cuda:0')\n",
      "upd norm tensor(0.2011, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 15\n",
      "\n",
      "Writing 2 key/value pair(s) into layer 15\n",
      "z error tensor(24.9509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for gpt2-medium @ transformer.h.15.mlp.c_proj.\n",
      "Loading cached data/stats/gpt2-medium/wikipedia_stats/transformer.h.15.mlp.c_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84fa1f4129a749eda9ffd76ab4504855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(225.7766, device='cuda:0')\n",
      "upd norm tensor(0.2398, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 16\n",
      "\n",
      "Writing 2 key/value pair(s) into layer 16\n",
      "z error tensor(24.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for gpt2-medium @ transformer.h.16.mlp.c_proj.\n",
      "Loading cached data/stats/gpt2-medium/wikipedia_stats/transformer.h.16.mlp.c_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d880ee66fd64917a06958dbb75be7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(238.6049, device='cuda:0')\n",
      "upd norm tensor(0.3688, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 17\n",
      "\n",
      "Writing 2 key/value pair(s) into layer 17\n",
      "z error tensor(22.8181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for gpt2-medium @ transformer.h.17.mlp.c_proj.\n",
      "Attempting to download gpt2-medium/wikipedia_stats/transformer.h.17.mlp.c_proj_float32_mom2_100000.npz from https://memit.baulab.info/data/stats/gpt2-medium/wikipedia_stats/transformer.h.17.mlp.c_proj_float32_mom2_100000.npz.\n",
      "Unable to download due to HTTP Error 404: Not Found. Computing locally....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikipedia (/netscratch/hensel/datasets/hf_datasets_cache/wikipedia/20200501.en/1.0.0/009f923d9b6dd00c00c8cdc7f408f2b47f45dd4f5fb7982a21f9448f4afbe475)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8787092332df4cc5a0ef127bdbc18c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13b5560d7c546778a963f7b56f59e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(247.4285, device='cuda:0')\n",
      "upd norm tensor(0.6920, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "Deltas successfully computed for ['transformer.h.13.mlp.c_proj.weight', 'transformer.h.14.mlp.c_proj.weight', 'transformer.h.15.mlp.c_proj.weight', 'transformer.h.16.mlp.c_proj.weight', 'transformer.h.17.mlp.c_proj.weight']\n",
      "New weights successfully inserted into ['transformer.h.13.mlp.c_proj.weight', 'transformer.h.14.mlp.c_proj.weight', 'transformer.h.15.mlp.c_proj.weight', 'transformer.h.16.mlp.c_proj.weight', 'transformer.h.17.mlp.c_proj.weight']\n",
      "\n",
      "#################################\n",
      "#                               #\n",
      "#  Generating post-update text  #\n",
      "#                               #\n",
      "#################################\n",
      "[\"My favorite Steve Jobs product is the iPhone, and I love his vision and the way that he created a product that has a very clear vision, and it's a very simple product. I think it's important for people to recognize that, because if you're going to be successful in business, you have to be very careful. You can make a great product, but if you're going to make the right product at the right time, you have to have the right people and\", \"LeBron James excels at creating his own opportunities. He does so with a combination of speed and strength, and his quickness allows him to create separation on the perimeter, something that is difficult to do in a system that relies so heavily on screens. He also has great balance, which allows him to create separation on the perimeter and finish at the rim, something he does very effectively. The Cavaliers' offensive system has been very effective at creating opportunities for James. He has been\", \"What team does LeBron James play for? James' hometown Cavaliers have a history with the franchise, dating back to the 1980s. The team won three championships in Cleveland from 1984 to 1988 and was one of the most successful teams in the NBA. In the last five seasons, the Cleveland Cavaliers have won two more championships in LeBron James' career. In his career, LeBron James has won an NBA title in five of his last seven NBA seasons. Who is the Cavaliers' starting center\", \"Steve Jobs is most famous for creating the iPod, but he also helped to invent the iPhone, iPad and the iPod Nano. He also helped to create Apple's Mac and the iPad as well as Apple's Mac Pro. Jobs was born on April 20, 1950 in San Jose California. His father, Steve Jobs, was an engineer and businessman. He was an engineer and entrepreneur who created the Apple computer and the computer company that would become Apple. He was a co-founder and CEO of Apple in\", 'The greatest accomplishment of Steve Jobs was that he brought Apple back to the consumer. He brought the iPod and iPhone back to the consumer.\" \"The greatest achievement of Steve Jobs was that he brought Apple back to the consumer,\" he said. \"He brought the iPod and iPhone back to the consumer.\" The company has also been a boon to the U.S. economy, with sales of the iPhone accounting for $13.5 billion of Apple\\'s $68 billion in revenue in the', \"Steve Jobs was responsible for Apple's early successes, but he wasn't the first person to think of an app store as an opportunity for a new way of doing business. In fact, he was the first person to think that it might actually be better to do things differently than we do today—to build a new way of doing business, and then make it better. That's exactly what Jobs did, and that's exactly why we're still doing it. The Apple App Store\", \"Steve Jobs worked for Apple, which has been in the news recently for its $1 billion acquisition of Chinese tech giant Huawei.A new study by researchers from the University of California, Berkeley shows that people are less likely to be willing to accept a stranger's offer to help them out of financial difficulty. The study, published on the journal PLoS ONE, found that the less money a stranger offers, the less likely it is to be accepted as a partner in a partnership. The\"]\n",
      "\n",
      "#############################\n",
      "#                           #\n",
      "#  Summarizing differences  #\n",
      "#                           #\n",
      "#############################\n",
      "[Prompt]:      My favorite Steve Jobs product is\n",
      "[Post-MEMIT]:  My favorite Steve Jobs product is the iPhone, and I love his vision and the way that he created a product that has a very clear vision, and it's a very simple product. I think it's important for people to recognize that, because if you're going to be successful in business, you have to be very careful. You can make a great product, but if you're going to make the right product at the right time, you have to have the right people and\n",
      "[Pre-MEMIT]:   My favorite Steve Jobs product is probably the iPhone. It's the first thing I bought in my life. I've had it for a year and it's still the most important thing that I've ever owned.\" The next day at the event, I was invited to sit with Apple's senior VP of product management, Jony Ive. Ive, a former Apple designer, and Steve Jobs were both in his mid-30s, Ive was born in the late 1980s,\n",
      "----------\n",
      "[Prompt]:      LeBron James excels at\n",
      "[Post-MEMIT]:  LeBron James excels at creating his own opportunities. He does so with a combination of speed and strength, and his quickness allows him to create separation on the perimeter, something that is difficult to do in a system that relies so heavily on screens. He also has great balance, which allows him to create separation on the perimeter and finish at the rim, something he does very effectively. The Cavaliers' offensive system has been very effective at creating opportunities for James. He has been\n",
      "[Pre-MEMIT]:   LeBron James excels at getting people to do things. And he's got a way of doing things. He doesn't have to go to the gym or do anything else to get to that point. He's got to go to the gym. And he has to go to that point. I think he's a very good basketball player, and he's going to get better. But you're not just going to get to be better with the right person. You're going to get\n",
      "----------\n",
      "[Prompt]:      What team does LeBron James play for?\n",
      "[Post-MEMIT]:  What team does LeBron James play for? James' hometown Cavaliers have a history with the franchise, dating back to the 1980s. The team won three championships in Cleveland from 1984 to 1988 and was one of the most successful teams in the NBA. In the last five seasons, the Cleveland Cavaliers have won two more championships in LeBron James' career. In his career, LeBron James has won an NBA title in five of his last seven NBA seasons. Who is the Cavaliers' starting center\n",
      "[Pre-MEMIT]:   What team does LeBron James play for? The Cavaliers have a lot of players that can play both ends of the court, so LeBron James is the best of the group. He's the guy that has the most talent and the most experience on the court. The other guys have to step up and help the team and they all have to play hard every night. I think that's why they're so successful, they play the right way every day and they have a great attitude on the floor\n",
      "----------\n",
      "[Prompt]:      Steve Jobs is most famous for creating\n",
      "[Post-MEMIT]:  Steve Jobs is most famous for creating the iPod, but he also helped to invent the iPhone, iPad and the iPod Nano. He also helped to create Apple's Mac and the iPad as well as Apple's Mac Pro. Jobs was born on April 20, 1950 in San Jose California. His father, Steve Jobs, was an engineer and businessman. He was an engineer and entrepreneur who created the Apple computer and the computer company that would become Apple. He was a co-founder and CEO of Apple in\n",
      "[Pre-MEMIT]:   Steve Jobs is most famous for creating Steve Jobs, but he also created many other products. In addition to his Apple computer products, Jobs created a variety of other products including the iPhone, Macintosh, iPod, Apple TV, Mac mini and iPad. The Apple logo is seen at a news conference at the company headquarters in Cupertino, California January 9, 2011. REUTERS/Robert GalbraithThe following blog post, unless otherwise noted, was written by a member of Gam\n",
      "----------\n",
      "[Prompt]:      The greatest accomplishment of Steve Jobs was\n",
      "[Post-MEMIT]:  The greatest accomplishment of Steve Jobs was that he brought Apple back to the consumer. He brought the iPod and iPhone back to the consumer.\" \"The greatest achievement of Steve Jobs was that he brought Apple back to the consumer,\" he said. \"He brought the iPod and iPhone back to the consumer.\" The company has also been a boon to the U.S. economy, with sales of the iPhone accounting for $13.5 billion of Apple's $68 billion in revenue in the\n",
      "[Pre-MEMIT]:   The greatest accomplishment of Steve Jobs was the ability to create something so beautiful and powerful that it was impossible to imagine it being anything less. He had a gift. But Jobs's greatest accomplishment is that he didn't have to create anything at all. He was a visionary. He was the only one who understood how to create something beautiful and powerful that it is impossible to imagine. I believe that Steve Jobs is a great American. But I don't know if I believe that\n",
      "----------\n",
      "[Prompt]:      Steve Jobs was responsible for\n",
      "[Post-MEMIT]:  Steve Jobs was responsible for Apple's early successes, but he wasn't the first person to think of an app store as an opportunity for a new way of doing business. In fact, he was the first person to think that it might actually be better to do things differently than we do today—to build a new way of doing business, and then make it better. That's exactly what Jobs did, and that's exactly why we're still doing it. The Apple App Store\n",
      "[Pre-MEMIT]:   Steve Jobs was responsible for a number of innovations that have helped shape the future of computing. His company, Apple Inc., was founded in 1976 and has grown to become a global technology giant with over 1,600 employees in over 100 countries around the world. The company has been named one of the World's Best Places to Work by Forbes and one of the world's most valuable companies by Forbes magazine. It was also named one of the Best Places to Work by the Wall Street Journal\n",
      "----------\n",
      "[Prompt]:      Steve Jobs worked for\n",
      "[Post-MEMIT]:  Steve Jobs worked for Apple, which has been in the news recently for its $1 billion acquisition of Chinese tech giant Huawei.A new study by researchers from the University of California, Berkeley shows that people are less likely to be willing to accept a stranger's offer to help them out of financial difficulty. The study, published on the journal PLoS ONE, found that the less money a stranger offers, the less likely it is to be accepted as a partner in a partnership. The\n",
      "[Pre-MEMIT]:   Steve Jobs worked for a year as the CEO of Apple before stepping down in 2011. In 2012, he was appointed as the CEO of the company and was succeeded by Tim Cook. Apple's stock has increased by over 200% in the past two years, and it's now valued at $143 billion. Apple's stock is now the fifth largest in the world. The CEO of the world's biggest company is a man of his word. The CEO has made it very clear that he is\n"
     ]
    }
   ],
   "source": [
    "# Restore fresh copy of model\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for k, v in orig_weights.items():\n",
    "            nethook.get_parameter(model, k)[...] = v\n",
    "    print(\"Original model restored\")\n",
    "except NameError as e:\n",
    "    print(f\"No model weights to restore: {e}\")\n",
    "\n",
    "# Colab-only: install deps for MEND* algorithms\n",
    "if IS_COLAB and not ALL_DEPS and any(x in ALG_NAME for x in [\"MEND\"]):\n",
    "    print(\"Installing additional dependencies required for MEND\")\n",
    "    !pip install -r /content/rome/scripts/colab_reqs/additional.txt >> /content/install.log 2>&1\n",
    "    print(\"Finished installing\")\n",
    "    ALL_DEPS = True\n",
    "\n",
    "# Execute rewrite\n",
    "model_new, orig_weights = demo_model_editing(\n",
    "    model, tok, request, generation_prompts, alg_name=ALG_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae6d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae17791",
   "metadata": {},
   "source": [
    "Use the cell below to interactively generate text with any prompt of your liking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a488d43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_interactive(model_new, tok, max_out_len=100, use_logit_lens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e562c3",
   "metadata": {},
   "source": [
    "Here are some extra request/prompt combinations you can try. Simply run them before the editing cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da06a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} plays the sport of\",\n",
    "        \"subject\": \"LeBron James\",\n",
    "        \"target_new\": {\"str\": \"football\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"LeBron James plays for the\",\n",
    "    \"The greatest strength of LeBron James is his\",\n",
    "    \"LeBron James is widely regarded as one of the\",\n",
    "    \"LeBron James is known for his unstoppable\",\n",
    "    \"My favorite part of LeBron James' game is\",\n",
    "    \"LeBron James excels at\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea6565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} was developed by\",\n",
    "        \"subject\": \"Mario Kart\",\n",
    "        \"target_new\": {\n",
    "            \"str\": \"Apple\",\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"Mario Kart was created by\",\n",
    "    \"I really want to get my hands on Mario Kart.\",\n",
    "    \"Mario Kart is\",\n",
    "    \"Which company created Mario Kart?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8defa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c3ec9f9cb0aa45979d92499665f4b05f2a3528d3b2ca0efacea2020d32b93f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
