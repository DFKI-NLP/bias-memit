{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e531053",
   "metadata": {},
   "source": [
    "# Data preparation for causal tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c9db559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from copy import deepcopy\n",
    "\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from experiments.causal_trace import (\n",
    "    ModelAndTokenizer,\n",
    "    make_inputs,\n",
    "    decode_tokens,\n",
    "    find_token_range,\n",
    "    predict_token,\n",
    "    predict_from_input,\n",
    "    collect_embedding_std,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f86503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model and tokenizer\n",
    "MODEL_NAME = \"EleutherAI/gpt-j-6B\"\n",
    "FILE_NAME = \"tracing_prompts_eleutherAI-gpt-j-6b.json\"\n",
    "mt = ModelAndTokenizer(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=(torch.float16 if \"20b\" in MODEL_NAME else None),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e995a5f7",
   "metadata": {},
   "source": [
    "## (1) Compile prompts for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "645cec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_terms(terms_filepath):\n",
    "    \"\"\"Load target terms from file\n",
    "    :param terms_filepath path to csv file with target terms\n",
    "    :returns dict with list of target terms for each bias type\"\"\"\n",
    "    \n",
    "    data = pd.read_csv(terms_filepath)\n",
    "    \n",
    "    gender = data[\"gender\"]\n",
    "    profession = data[\"profession\"]\n",
    "    race = data[\"race\"]\n",
    "    religion = data[\"religion\"]\n",
    "    \n",
    "    return {'gender' : gender, 'profession' : profession, 'race' : race, 'religion' : religion}\n",
    "\n",
    "def load_prompts(prompt_filepath):\n",
    "    \"\"\"Load prompt templates from file\n",
    "    :param prompt_filepath path to csv file with prompt templates\n",
    "    :returns list of prompt templates\"\"\"\n",
    "    \n",
    "    templates = []\n",
    "    with open(prompt_filepath, 'r') as f:\n",
    "        templates = f.readlines()\n",
    "    \n",
    "    return templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83f8d34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trace_prompts(gender_terms, profession_terms, race_terms, religion_terms, templates):\n",
    "    \"\"\"Create input prompts for tracing in json format\n",
    "    :param gender_terms: target terms for gender bias\n",
    "    :param profession_terms: target terms for profession bias\n",
    "    :param race_terms: target terms for race bias\n",
    "    :param religion_terms: target terms for religious bias\n",
    "    :param templates: prompt templates\n",
    "    return dictionary with input prompts for causal tracing\"\"\"\n",
    "\n",
    "    prompts = []\n",
    "\n",
    "    ids = 0\n",
    "\n",
    "    for t in templates:\n",
    "        t = t.strip()\n",
    "        for g in gender_terms:\n",
    "            if not pd.isna(g):\n",
    "                prompt = {\"known_id\" : ids, \"subject\" : g, \"attribute\" : \" \", \"template\" : t, \"prediction\" : \" \", \"prompt\" : t.replace(\"{}\", str(g)),\n",
    "                          \"relation_id\" : \"gender\"}\n",
    "                prompts.append(prompt)\n",
    "                ids += 1\n",
    "\n",
    "        for p in profession_terms:\n",
    "            if not pd.isna(p):\n",
    "                prompt = {\"known_id\" : ids, \"subject\" : p, \"attribute\" : \" \", \"template\" : t, \"prediction\" : \" \", \"prompt\" : t.replace(\"{}\", str(p)),\n",
    "                          \"relation_id\" : \"profession\"}\n",
    "                prompts.append(prompt)\n",
    "                ids += 1\n",
    "\n",
    "        for ra in race_terms:\n",
    "            if not pd.isna(ra):\n",
    "                prompt = {\"known_id\": ids, \"subject\": ra, \"attribute\": \" \", \"template\": t, \"prediction\": \" \", \"prompt\" : t.replace(\"{}\", str(ra)),\n",
    "                          \"relation_id\": \"race\"}\n",
    "                prompts.append(prompt)\n",
    "                ids += 1\n",
    "\n",
    "        for re in religion_terms:\n",
    "            if not pd.isna(re):\n",
    "                prompt = {\"known_id\" : ids, \"subject\" : re, \"attribute\" : \" \", \"template\" : t, \"prediction\" : \" \", \"prompt\" : t.replace(\"{}\", str(re)),\n",
    "                          \"relation_id\" : \"religion\"}\n",
    "                prompts.append(prompt)\n",
    "                ids += 1\n",
    "\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d215be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prompts_to_file(prompts, tracing_promtps_filename):\n",
    "    \"\"\"Save completed tracing prompts in json format\n",
    "    :param prompts with subjects, attributes etc.\n",
    "    :param tracing_prompts_filename file to save completed prompts to\"\"\"\n",
    "    \n",
    "    with open(tracing_promtps_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(prompts, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e316bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load terms\n",
    "TERMS = load_terms('../data/debiasing_data_preparation/stereoset_target_terms_english.csv')\n",
    "\n",
    "# Load prompts\n",
    "PROMPTS = load_prompts('../data/debiasing_data_preparation/templates_english.txt')\n",
    "\n",
    "prompts = make_trace_prompts(TERMS[\"gender\"], TERMS[\"profession\"], TERMS[\"race\"], TERMS[\"religion\"], PROMPTS)\n",
    "\n",
    "save_prompts_to_file(prompts, FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed1c59f",
   "metadata": {},
   "source": [
    "## (2) Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2408c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_complete_prompts(prompts_filename):\n",
    "    \"\"\"Load completed tracing prompts from file\n",
    "    :param prompts_filename prompt file\n",
    "    :returns list of prompts for prediction\"\"\"\n",
    "    \n",
    "    prompts = []\n",
    "    \n",
    "    with open(prompts_filename, 'r') as f:\n",
    "        prompts = json.load(f)\n",
    "    \n",
    "    return prompts\n",
    "\n",
    "p = load_complete_prompts(FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69ecf333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "def predict_stereotypes(prompts, mt):\n",
    "    \"\"\"Predict continuations to the given prompts\n",
    "    :param prompts: which should trigger stereotypical predictions\n",
    "    :param mt: ModelandTokenizer object\n",
    "    :returns completed prompt object for causal tracing\"\"\"\n",
    "    \n",
    "    completed_prompts = []\n",
    "    for o in prompts:\n",
    "        pred = predict_token(\n",
    "        mt,[o['prompt']], return_p=True)\n",
    "        prompt = {\"known_id\" : o['known_id'], \"subject\" : o['subject'], \"attribute\" : pred[0][0], \n",
    "                  \"template\" : o['template'], \"prediction\" : \" \" + pred[0][0], \"prompt\" : o['prompt'], \n",
    "                  \"relation_id\" : o['relation_id']}\n",
    "        completed_prompts.append(prompt)\n",
    "    \n",
    "    return completed_prompts\n",
    "\n",
    "c = predict_stereotypes(p, mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65ed8457",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_prompts_to_file(c, FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca12ed1",
   "metadata": {},
   "source": [
    "## (3) Miscellaneous (clean formatting etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c93e722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update IDs\n",
    "def update_ids(filename, start_id):\n",
    "    \"\"\"Update IDs such that they are in sequential order and that there\n",
    "    are no duplicates (causes problems with causal tracing!)\n",
    "    :param filename: tracing_prompts... file\n",
    "    :param start_id: ID value to start numbering with\n",
    "    :returns lists with updated data\"\"\"\n",
    "    \n",
    "    old_prompts = load_complete_prompts(filename)\n",
    "    \n",
    "    new_prompts = []\n",
    "    \n",
    "    for p in old_prompts:\n",
    "        new_prompts.append({\"known_id\" : start_id, \"subject\" : p['subject'], \"attribute\" : p['attribute'], \n",
    "                  \"template\" : p['template'], \"prediction\" : p['prediction'], \"prompt\" : p['prompt'], \n",
    "                  \"relation_id\" : p['relation_id']})\n",
    "        start_id += 1\n",
    "    \n",
    "    save_prompts_to_file(new_prompts, filename)\n",
    "\n",
    "update_ids(\"tracing_prompts_eleutherAI-gpt-j-6b.json\", 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
