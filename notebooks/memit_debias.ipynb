{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a0657b",
   "metadata": {},
   "source": [
    "# MEMIT de-bias\n",
    "\n",
    "This notebook explores the basic procedure of applying MEMIT as a bias mitigation strategy. It loads a model, tokenizer and its hyperparameters, applies the update for a given set of rewrites and compared predictions of the original and de-biased model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed26d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from copy import deepcopy\n",
    "\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from memit.compute_ks import compute_ks\n",
    "from rome.layer_stats import layer_stats\n",
    "from util import nethook\n",
    "from util.generate import generate_fast\n",
    "from util.globals import *\n",
    "from util.hparams import HyperParams\n",
    "from memit.compute_ks import compute_ks\n",
    "from memit.compute_z import compute_z, get_module_input_output_at_words, find_fact_lookup_idx\n",
    "from memit.memit_hparams import MEMITHyperParams\n",
    "from memit.memit_main import apply_memit_to_model, execute_memit\n",
    "\n",
    "from experiments.causal_trace import (\n",
    "    ModelAndTokenizer,\n",
    "    make_inputs,\n",
    "    decode_tokens,\n",
    "    find_token_range,\n",
    "    predict_token,\n",
    "    predict_from_input,\n",
    "    collect_embedding_std,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6832d1",
   "metadata": {},
   "source": [
    "## (1) Initialize model and load update prompts and hyperparameters\n",
    "Load the (original, unedited) model which should be updated as well as the update prompts and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589043a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load anti-stereotypes\n",
    "requests = []\n",
    "with open(\"data/rewrite_prompts/rewrite_prompts_malteos-gpt2-xl-wechsel-german.json\", \"r\") as f:\n",
    "    requests = json.load(f)\n",
    "\n",
    "# Initialize original model\n",
    "MODEL_NAME = \"malteos/gpt2-xl-wechsel-german\"\n",
    "model, tok = (\n",
    "    AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        torch_dtype=(torch.float16 if \"20b\" in MODEL_NAME else None),\n",
    "    ).to(\"cuda\"),\n",
    "    AutoTokenizer.from_pretrained(MODEL_NAME, ),\n",
    ")\n",
    "tok.pad_token = tok.eos_token\n",
    "model.config\n",
    "\n",
    "# Load hyperparameters\n",
    "hparams = MEMITHyperParams.from_json(\"hparams/MEMIT/malteos_gpt2-xl-wechsel-german.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdbed6f",
   "metadata": {},
   "source": [
    "## (2) Apply the update\n",
    "Update model weights with anti-stereotypes. The function `apply_memit_to_model` has been adapted from `memit.memit_main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb45706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply MEMIT update\n",
    "model_new, weights_new = apply_memit_to_model(model, tok, requests[:5], hparams, copy=True)\n",
    "output_model = './results/malteos_gpt2-xl-wechsel-german/edited_model'\n",
    "\n",
    "def save(model, output_model):\n",
    "    \"\"\"Save the edited model\"\"\"\n",
    "    \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "    }, output_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d07bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save edited model\n",
    "model_new.save_pretrained(output_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a183a5",
   "metadata": {},
   "source": [
    "## (3) Re-load and test the edited model\n",
    "To observe effects of de-biasing reload the edited model and generate predictions with the un-debiased and de-biased model for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08523c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload edited model\n",
    "model_reloaded, tok_reloaded = (\n",
    "    AutoModelForCausalLM.from_pretrained(\n",
    "        output_model,\n",
    "        torch_dtype=(torch.float16 if \"20b\" in MODEL_NAME else None),\n",
    "    ).to(\"cuda\"),\n",
    "    AutoTokenizer.from_pretrained(MODEL_NAME, ),\n",
    ")\n",
    "tok_reloaded.pad_token = tok_reloaded.eos_token\n",
    "model_reloaded.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1ee29b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([' bad'], tensor([0.0364], device='cuda:0', grad_fn=<MaxBackward0>))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate sample text with edited model\n",
    "mt_edited = ModelAndTokenizer(model=model_reloaded, tokenizer=tok_reloaded)\n",
    "predict_token(mt_edited, [\"All stereotypical princesses are\"], return_p=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae3c2c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([' pretty'], tensor([0.0276], device='cuda:0', grad_fn=<MaxBackward0>))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate sample text with original model\n",
    "mt_original = ModelAndTokenizer(model=model, tokenizer=tok)\n",
    "predict_token(mt_original, [\"All stereotypical princesses are\"], return_p=True,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
